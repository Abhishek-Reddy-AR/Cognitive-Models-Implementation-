{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f7ca703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required modules\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c07c1d",
   "metadata": {},
   "source": [
    "## Q1:GCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97c1dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate similarity score\n",
    "def cal_sim(stored,stimulus,alpha,beta):\n",
    "    d=0\n",
    "    for i in range(len(stimulus)):\n",
    "        d+=alpha[i]*(stored[i]-stimulus[i])\n",
    "    #if the distance measure is negative ,taking the absolute value\n",
    "    if d<0:\n",
    "        d=abs(d)\n",
    "    #calculating similarity score from distance\n",
    "    sim_score = np.exp(-beta*d)\n",
    "    #returning score\n",
    "    return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c5cc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make category prediction when given test sample\n",
    "def prediction(stimulus,labels_unique,stimuli_unique,alpha,beta,gamma,count):\n",
    "    #initializing array to store label probabilities\n",
    "    label_probs=np.zeros(len(labels_unique))\n",
    "    #for each unique label\n",
    "    for i in range(len(labels_unique)):\n",
    "        #for each unique stimuli\n",
    "        for j in range(len(stimuli_unique)):\n",
    "            #multiplying the count(stimuli,category)*sim(unique_stimuli,test_stimuli)\n",
    "            label_probs[i]+=count[(int(stimuli_unique[j][0]),int(stimuli_unique[j][1]),i+1)]*cal_sim(stimuli_unique[j],stimulus,alpha,beta)\n",
    "        #multiplying categorys by their respective gamma values\n",
    "        label_probs[i]=label_probs[i]*gamma[i]\n",
    "    #getting the category probabilities\n",
    "    label_probs=label_probs/sum(label_probs)\n",
    "    #returning the category with highest probability\n",
    "    return np.argmax(label_probs)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5f890c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    #loading total train data\n",
    "    total_train=pd.read_csv('X.csv',header=None)\n",
    "    #loading test data\n",
    "    test=pd.read_csv('y.csv',header=None)\n",
    "    #conversion to array\n",
    "    total_train=np.array(total_train)\n",
    "    #shuffling total train data to split it into train and validation data\n",
    "    np.random.shuffle(total_train)\n",
    "    #splitting into train and validation data\n",
    "    validate=total_train[60:]\n",
    "    train=total_train[:60]\n",
    "    #conversion to array\n",
    "    test=np.array(test)\n",
    "    return total_train,train,validate,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59ff36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_return_count(data):\n",
    "    #getting unique stimulus values in train\n",
    "    stimuli_unique = np.unique(data[:,:-1],axis=0)\n",
    "    #getting unique label values in train\n",
    "    labels_unique = np.unique(data[:,-1],axis=0)\n",
    "    #to store the frequencies of (stimulus,category)\n",
    "    count={}\n",
    "    #initializing all possible combinations to zeros\n",
    "    for i in stimuli_unique:\n",
    "        for j in labels_unique:\n",
    "            count[(int(i[0]),int(i[1]),int(j))]=0\n",
    "    #getting the counts\n",
    "    for i in data:\n",
    "        count[(int(i[0]),int(i[1]),int(i[2]))]+=1\n",
    "    return count,labels_unique,stimuli_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ad611ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return optimal parameters\n",
    "def optimal_params(validate,labels_unique,stimuli_unique,count):\n",
    "    #lists of possible alpha,possible gamma values for tuning\n",
    "    possible_alphas=[[2,1],[4,1],[1.5,1]]\n",
    "    possible_gammas=[[1,1.5,0.5],[1,2,0.5],[1,1.5,0.7]]\n",
    "    beta=1\n",
    "    #finding the optimal alpha and gamma pair that gives the max accuracy on the validation data\n",
    "    max_acc=0\n",
    "    for alpha in possible_alphas:\n",
    "         for gamma in possible_gammas:\n",
    "            curr_acc=0\n",
    "            for i in range(np.shape(validate)[0]-1):\n",
    "                pred=prediction(validate[i][:-1],labels_unique,stimuli_unique,alpha,beta,gamma,count)\n",
    "                if pred==validate[i][-1]:\n",
    "                    curr_acc+=1\n",
    "            if curr_acc>max_acc:\n",
    "                max_acc=curr_acc\n",
    "                optimal_alpha=alpha\n",
    "                optimal_gamma=gamma\n",
    "    #storing optimal values\n",
    "    alpha=optimal_alpha\n",
    "    gamma=optimal_gamma\n",
    "    return alpha,beta,gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e8c6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_prediction():\n",
    "    #loading data\n",
    "    total_train,train,validate,test=load_data()\n",
    "    #getting count dict on train data\n",
    "    count,labels_unique,stimuli_unique=to_return_count(train)\n",
    "    #getting optimal parameters\n",
    "    alpha,beta,gamma=optimal_params(validate,labels_unique,stimuli_unique,count)\n",
    "    #getting count dict on whole train data\n",
    "    count,labels_unique,stimuli_unique=to_return_count(train)\n",
    "    #to store q1 predictions\n",
    "    q1_preds=[]\n",
    "    for i in range(len(test)):\n",
    "        q1_preds.append(prediction(test[i],labels_unique,stimuli_unique,alpha,beta,gamma,count))\n",
    "    return q1_preds,alpha,beta,gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60262a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7bceb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpa: [2, 1]\n",
      "gamma: [1, 1.5, 0.5]\n",
      "beta: 1\n",
      "test stimulus: [74 67]\n",
      "predicted category: 2\n",
      "test stimulus: [69 63]\n",
      "predicted category: 2\n",
      "test stimulus: [92 81]\n",
      "predicted category: 3\n",
      "test stimulus: [64 61]\n",
      "predicted category: 2\n",
      "test stimulus: [66 84]\n",
      "predicted category: 2\n",
      "test stimulus: [76 68]\n",
      "predicted category: 3\n",
      "test stimulus: [61 58]\n",
      "predicted category: 2\n",
      "test stimulus: [64 76]\n",
      "predicted category: 2\n",
      "test stimulus: [68 66]\n",
      "predicted category: 2\n",
      "test stimulus: [34 61]\n",
      "predicted category: 1\n"
     ]
    }
   ],
   "source": [
    "q1_preds,alpha,beta,gamma=q1_prediction()\n",
    "print('alpa:',alpha)\n",
    "print('gamma:',gamma)\n",
    "print('beta:',beta)\n",
    "test = pd.read_csv('y.csv',header=None)\n",
    "test = np.array(test)\n",
    "for i in range(len(test)):\n",
    "    print('test stimulus:',test[i])\n",
    "    print('predicted category:',q1_preds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b36d9",
   "metadata": {},
   "source": [
    "## Q2:RCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbbb5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dLocalMAP:\n",
    "    \"\"\"\n",
    "    See Anderson (1990, 1991)\n",
    "    'Categories' renamed 'clusters' to avoid confusion.\n",
    "    Discrete version.\n",
    "    \n",
    "    Stimulus format is a list of integers from 0 to n-1 where n is the number\n",
    "    of possible features (e.g. [1,0,1])\n",
    "    \n",
    "    args: c, alphas\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        self.partition = [[]]\n",
    "        self.c, self.alpha = args\n",
    "        self.alpha0 = sum(self.alpha.T)\n",
    "        self.N = 0\n",
    "        \n",
    "    def probClustVal(self, k, i, val):\n",
    "        \"\"\"Find P(j|k)\"\"\"\n",
    "        cj = len([x for x in self.partition[k] if x[i]==val])\n",
    "        nk = len(self.partition[k])\n",
    "        return (cj + self.alpha[i][val])/(nk + self.alpha0[i])\n",
    "    \n",
    "    def condclusterprob(self, stim, k):\n",
    "        \"\"\"Find P(F|k)\"\"\"\n",
    "        pjks = []\n",
    "        for i in range(len(stim)):\n",
    "            cj = len([x for x in self.partition[k] if x[i]==stim[i]])\n",
    "            nk = len(self.partition[k])\n",
    "            pjks.append( (cj + self.alpha[i][stim[i]])/(nk + self.alpha0[i]) )\n",
    "        return np.product( pjks )\n",
    "    \n",
    "    def posterior(self, stim):\n",
    "        \"\"\"Find P(k|F) for each cluster\"\"\"\n",
    "        pk = np.zeros( len(self.partition) )\n",
    "        pFk = np.zeros( len(self.partition) )\n",
    "        # existing clusters:\n",
    "        for k in range(len(self.partition)):\n",
    "            pk[k] = self.c * len(self.partition[k])/ ((1-self.c) + self.c * self.N)\n",
    "            if len(self.partition[k])==0: # case of new cluster\n",
    "                pk[k] = (1-self.c) / (( 1-self.c ) + self.c * self.N)\n",
    "            pFk[k] = self.condclusterprob( stim, k)\n",
    "        # put it together\n",
    "        pkF = (pk*pFk)#/ sum( pk*pFk )\n",
    "        return pkF\n",
    "    \n",
    "    def stimulate(self, stim):\n",
    "        \"\"\"Argmax of P(k|F) + P(0|F)\"\"\"\n",
    "        winner = np.argmax( self.posterior(stim) )\n",
    "        \n",
    "        #limiting the number of clusters to only three\n",
    "        if len(self.partition[winner]) == 0 and winner<3:\n",
    "            self.partition.append( [] )\n",
    "        #if the winner is >=3 then assigning as the cluster number among 0 to 2 that has highest posterior\n",
    "        else:\n",
    "            winner=np.argmax(self.posterior(stim)[:3])\n",
    "        self.partition[winner].append(stim)\n",
    "        \n",
    "        self.N += 1\n",
    "    \n",
    "    def query(self, stimulus):\n",
    "        \"\"\"Queried value should be -1.\"\"\"\n",
    "        qdim = -1\n",
    "        for i in range(len(stimulus)):\n",
    "            if stimulus[i] < 0:\n",
    "                if qdim != -1:\n",
    "                    raise Exception( \"ERROR: Multiple dimensions queried.\")\n",
    "                qdim = i\n",
    "        \n",
    "        self.N = sum([len(x) for x in self.partition])\n",
    "        \n",
    "        pkF = self.posterior(stimulus)\n",
    "        pkF = pkF[:-1] / sum(pkF[:-1]) # eliminate `new cluster' prob\n",
    "        pjF = np.array( [sum( [ pkF[k] * self.probClustVal(k, qdim, j) \\\n",
    "                for k in range(len(self.partition)-1)] ) \n",
    "                for j in range(len( self.alpha[qdim] ))] )\n",
    "        \n",
    "        return pjF / sum(pjF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a419793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testlocalmapD():\n",
    "    #loading train data\n",
    "    train = pd.read_csv('X.csv',header=None)\n",
    "    #conversion to list\n",
    "    stims = np.array(train)  \n",
    "    for _ in range(1):\n",
    "        #'c' value is the probability that two objects belong to that same category,\n",
    "        #since there are 3 different categories in our data\n",
    "        #c=3/9=0.333\n",
    "        \n",
    "        #continuous variable to discrete variable conversion\n",
    "        #i have converted weights into 3 discrete values 0,1,2 by subtracting 30(hypothetical min weight value) and then dividing by 22 to get 3 bins\n",
    "        #i have converted heights into 3 discrete values 0,1,2 by subtracting 55(hypothetical min height value) and then dividing by 10 to get 3 bins\n",
    "        model = dLocalMAP([0.33333,np.ones((3,3))])\n",
    "        #shuffling train data\n",
    "        np.random.shuffle(stims)\n",
    "        #for each train data point\n",
    "        for s in stims:\n",
    "            #converting into discrete values\n",
    "            s[0]=(s[0]-30)//22\n",
    "            s[1]=(s[1]-55)//10\n",
    "            #subtracting 1 from category label\n",
    "            s[-1]=s[-1]-1\n",
    "            #conversion to list\n",
    "            s=list(s)\n",
    "            #adding to model\n",
    "            model.stimulate(s)\n",
    "        #reading test data\n",
    "        test = pd.read_csv('y.csv',header=None)\n",
    "        #conversion to array\n",
    "        test = np.array(test)\n",
    "        #for each test point\n",
    "        predictions=[]\n",
    "        for i in test:\n",
    "            #converting into discrete values\n",
    "            i[0]=(i[0]-30)//22\n",
    "            i[1]=(i[1]-55)//10\n",
    "            #adding category as -1\n",
    "            i=list(i)+[-1]\n",
    "            #printing the category prediction\n",
    "            predictions.append(np.argmax(model.query(i))+1)\n",
    "            #print('predicted category:',predictions[-1])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2014be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a6a5f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test stimulus: [74 67]\n",
      "predicted category: 3\n",
      "test stimulus: [69 63]\n",
      "predicted category: 2\n",
      "test stimulus: [92 81]\n",
      "predicted category: 3\n",
      "test stimulus: [64 61]\n",
      "predicted category: 2\n",
      "test stimulus: [66 84]\n",
      "predicted category: 2\n",
      "test stimulus: [76 68]\n",
      "predicted category: 3\n",
      "test stimulus: [61 58]\n",
      "predicted category: 2\n",
      "test stimulus: [64 76]\n",
      "predicted category: 2\n",
      "test stimulus: [68 66]\n",
      "predicted category: 2\n",
      "test stimulus: [34 61]\n",
      "predicted category: 1\n"
     ]
    }
   ],
   "source": [
    "q2_preds=testlocalmapD()\n",
    "test = pd.read_csv('y.csv',header=None)\n",
    "test = np.array(test)\n",
    "for i in range(len(test)):\n",
    "    print('test stimulus:',test[i])\n",
    "    print('predicted category:',q2_preds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c9ecb3",
   "metadata": {},
   "source": [
    "## Q3:showing  exchangeability of data does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de443bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 3, 2, 2, 3, 2, 2, 2, 1]\n",
      "[2, 2, 3, 2, 2, 3, 2, 2, 2, 1]\n",
      "[2, 2, 3, 2, 2, 3, 2, 2, 2, 1]\n",
      "[2, 2, 3, 2, 3, 3, 2, 2, 2, 1]\n",
      "[2, 2, 3, 2, 2, 3, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#there is shuffle function in the load data function itself,so each time we run the q1_prediction the data is exchanged\n",
    "for i in range(5):\n",
    "    curr_preds,alpha,beta,gamma=q1_prediction()\n",
    "    print(curr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc231237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 2, 2, 3, 2, 2, 2, 1]\n",
      "[3, 2, 3, 2, 2, 3, 2, 2, 2, 1]\n",
      "[3, 2, 3, 2, 2, 3, 2, 2, 2, 1]\n",
      "[3, 1, 3, 1, 2, 3, 1, 2, 2, 1]\n",
      "[3, 2, 3, 2, 2, 3, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#there is shuffle function in the testlocalmap function itself,so each time we run the q1_prediction the data is exchanged\n",
    "for i in range(5):\n",
    "    curr_preds=testlocalmapD()\n",
    "    print(curr_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0e23b",
   "metadata": {},
   "source": [
    "### please run the third part once more if there are any problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4352d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
